{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cda861cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained model\n",
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')\n",
    "\n",
    "# Load COCO class names (used for YOLO)\n",
    "classes = []\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = f.read().strip().split(\"\\n\")\n",
    "\n",
    "# Get the output layer names\n",
    "layer_names = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "# Open video\n",
    "cap = cv2.VideoCapture('example.mp4')\n",
    "\n",
    "# List to store tracked people centroids\n",
    "tracked_centroids = []\n",
    "\n",
    "# Function to calculate Intersection over Union (IOU) between two bounding boxes\n",
    "def calculate_IOU(box1, box2):\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    intersect_x1 = max(x1, x2)\n",
    "    intersect_y1 = max(y1, y2)\n",
    "    intersect_x2 = min(x1 + w1, x2 + w2)\n",
    "    intersect_y2 = min(y1 + h1, y2 + h2)\n",
    "\n",
    "    if intersect_x2 > intersect_x1 and intersect_y2 > intersect_y1:\n",
    "        intersect_area = (intersect_x2 - intersect_x1) * (intersect_y2 - intersect_y1)\n",
    "        box1_area = w1 * h1\n",
    "        box2_area = w2 * h2\n",
    "\n",
    "        iou = intersect_area / float(box1_area + box2_area - intersect_area)\n",
    "        return iou\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "# YOLO detection threshold and frame skip\n",
    "detection_threshold = 0.5\n",
    "frame_skip = 30\n",
    "\n",
    "max_people_count = 0  # Variable to keep track of the highest people count\n",
    "\n",
    "while cap.isOpened():\n",
    "    for _ in range(frame_skip - 1):\n",
    "        cap.read()\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        # Prepare frame for object detection (resize, normalization, etc.)\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Perform object detection\n",
    "        detections = net.forward(layer_names)\n",
    "\n",
    "        new_centroids = []\n",
    "\n",
    "        for detection in detections:\n",
    "            for obj in detection:\n",
    "                scores = obj[5:]\n",
    "                class_id = scores.argmax()\n",
    "                confidence = scores[class_id]\n",
    "\n",
    "                if classes[class_id] == 'person' and confidence > detection_threshold:\n",
    "                    bbox = obj[0:4] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                    bbox = tuple(bbox.astype(int))\n",
    "\n",
    "                    centroid = (bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2\n",
    "\n",
    "                    new_centroids.append(centroid)\n",
    "\n",
    "        # Update tracked centroids\n",
    "        if tracked_centroids:\n",
    "            updated_centroids = []\n",
    "            for centroid in new_centroids:\n",
    "                is_tracked = False\n",
    "                for tracked_centroid in tracked_centroids:\n",
    "                    if calculate_IOU((centroid[0], centroid[1], 1, 1), (tracked_centroid[0], tracked_centroid[1], 1, 1)) > 0.5:\n",
    "                        updated_centroids.append(tracked_centroid)\n",
    "                        is_tracked = True\n",
    "                        break\n",
    "                if not is_tracked:\n",
    "                    updated_centroids.append(centroid)\n",
    "            tracked_centroids = updated_centroids\n",
    "        else:\n",
    "            tracked_centroids = new_centroids\n",
    "\n",
    "        # Display tracked objects\n",
    "        for centroid in tracked_centroids:\n",
    "            x, y = int(centroid[0]), int(centroid[1])\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 0), -1)\n",
    "        \n",
    "        num_people = len(tracked_centroids)\n",
    "        if num_people > max_people_count:\n",
    "            max_people_count = num_people  # Update the maximum count\n",
    "        \n",
    "        cv2.putText(frame, f'People: {num_people}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('VIEW', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f'Highest people count in a frame: {max_people_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d59e73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
