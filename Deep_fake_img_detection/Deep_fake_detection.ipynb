{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d67fef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: (1428, 224, 224, 3)\n",
      "Validation images: (306, 224, 224, 3)\n",
      "Test images: (307, 224, 224, 3)\n",
      "Train labels: (1428,)\n",
      "Validation labels: (306,)\n",
      "Test labels: (307,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set paths to your real and fake image folders\n",
    "real_folder = r\"D:\\Deep_fake_detection\\archive (1)\\real_and_fake_face\\training_real\"\n",
    "fake_folder = r\"D:\\Deep_fake_detection\\archive (1)\\real_and_fake_face\\training_fake\"\n",
    "\n",
    "# Load and organize images\n",
    "real_images = [os.path.join(real_folder, image) for image in os.listdir(real_folder)]\n",
    "fake_images = [os.path.join(fake_folder, image) for image in os.listdir(fake_folder)]\n",
    "\n",
    "# Combine real and fake images\n",
    "all_images = real_images + fake_images\n",
    "labels = [1] * len(real_images) + [0] * len(fake_images)\n",
    "\n",
    "# Shuffle the images and labels\n",
    "combined = list(zip(all_images, labels))\n",
    "random.shuffle(combined)\n",
    "all_images, labels = zip(*combined)\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(all_images, labels, test_size=0.3, random_state=42)\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(test_images, test_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define image size for resizing\n",
    "image_size = (224, 224)\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=image_size)\n",
    "    img = img_to_array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return img\n",
    "\n",
    "# Preprocess training images\n",
    "train_images = np.array([preprocess_image(image) for image in train_images])\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Preprocess validation images\n",
    "val_images = np.array([preprocess_image(image) for image in val_images])\n",
    "val_labels = np.array(val_labels)\n",
    "\n",
    "# Preprocess testing images\n",
    "test_images = np.array([preprocess_image(image) for image in test_images])\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(\"Train images:\", train_images.shape)\n",
    "print(\"Validation images:\", val_images.shape)\n",
    "print(\"Test images:\", test_images.shape)\n",
    "print(\"Train labels:\", train_labels.shape)\n",
    "print(\"Validation labels:\", val_labels.shape)\n",
    "print(\"Test labels:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f77ee231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - 60s 1s/step - loss: 0.7564 - accuracy: 0.5182 - val_loss: 0.6894 - val_accuracy: 0.5784\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 59s 1s/step - loss: 0.6865 - accuracy: 0.5791 - val_loss: 0.6922 - val_accuracy: 0.5261\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 46s 1s/step - loss: 0.6841 - accuracy: 0.5903 - val_loss: 0.6839 - val_accuracy: 0.5850\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 49s 1s/step - loss: 0.6769 - accuracy: 0.6057 - val_loss: 0.6846 - val_accuracy: 0.5621\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 48s 1s/step - loss: 0.6566 - accuracy: 0.6162 - val_loss: 0.6815 - val_accuracy: 0.5752\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 48s 1s/step - loss: 0.6285 - accuracy: 0.6513 - val_loss: 0.7289 - val_accuracy: 0.5458\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 49s 1s/step - loss: 0.5744 - accuracy: 0.7045 - val_loss: 0.7481 - val_accuracy: 0.5784\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 49s 1s/step - loss: 0.5255 - accuracy: 0.7157 - val_loss: 0.7270 - val_accuracy: 0.5588\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 49s 1s/step - loss: 0.4511 - accuracy: 0.7773 - val_loss: 0.8393 - val_accuracy: 0.5556\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 47s 1s/step - loss: 0.3376 - accuracy: 0.8550 - val_loss: 1.0392 - val_accuracy: 0.5980\n",
      "10/10 [==============================] - 2s 231ms/step - loss: 1.0286 - accuracy: 0.5472\n",
      "Test accuracy: 0.5472312569618225\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(val_images, val_labels))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ce93d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict real or fake\n",
    "def predict_real_or_fake(image_path):\n",
    "    # Preprocess the image\n",
    "    img = preprocess_image(image_path)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = model.predict(img)\n",
    "    \n",
    "    # Set a threshold (e.g., 0.5)\n",
    "    threshold = 0.5\n",
    "    \n",
    "    # Classify as real or fake based on the threshold\n",
    "    if prediction >= threshold:\n",
    "        result = \"Fake\"\n",
    "    else:\n",
    "        result = \"Real\"\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cba710a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step\n",
      "Predicted Result: Fake\n"
     ]
    }
   ],
   "source": [
    "# Path to the uploaded image you want to predict\n",
    "uploaded_image_path = r\"D:\\time pass\\hbh.jpg\"\n",
    "# Predict whether the uploaded image is real or fake\n",
    "prediction_result = predict_real_or_fake(uploaded_image_path)\n",
    "print(\"Predicted Result:\", prediction_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ecdab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
