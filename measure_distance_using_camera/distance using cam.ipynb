{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f111cc6-c166-4d28-83e2-b7d559b8d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cb3d45b-c55b-4f43-827d-d3c208977a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance from camera to object(face) measured \n",
    "# centimeter \n",
    "Known_distance = 76.2\n",
    "  \n",
    "# width of face in the real world or Object Plane \n",
    "# centimeter \n",
    "Known_width = 14.3\n",
    "  \n",
    "# Colors \n",
    "GREEN = (0, 255, 0) \n",
    "RED = (0, 0, 255) \n",
    "WHITE = (255, 255, 255) \n",
    "BLACK = (0, 0, 0) \n",
    "  \n",
    "# defining the fonts \n",
    "fonts = cv2.FONT_HERSHEY_COMPLEX \n",
    "  \n",
    "# face detector object \n",
    "face_detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ea1806-5435-481a-98b6-9728d5482db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# focal length finder function \n",
    "def Focal_Length_Finder(measured_distance, real_width, width_in_rf_image): \n",
    "  \n",
    "    # finding the focal length \n",
    "    focal_length = (width_in_rf_image * measured_distance) / real_width \n",
    "    return focal_length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba68fce7-d7ea-4af7-937f-a1b3fb525ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance estimation function \n",
    "def Distance_finder(Focal_Length, real_face_width, face_width_in_frame): \n",
    "  \n",
    "    distance = (real_face_width * Focal_Length)/face_width_in_frame \n",
    "  \n",
    "    # return the distance \n",
    "    return distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f59eb73-414b-418d-8f03-0d6c18d89cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1513.3426573426573\n"
     ]
    }
   ],
   "source": [
    "def face_data(image): \n",
    "  \n",
    "    face_width = 0  # making face width to zero \n",
    "  \n",
    "    # converting color image to gray scale image \n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) \n",
    "  \n",
    "    # detecting face in the image \n",
    "    faces = face_detector.detectMultiScale(gray_image, 1.3, 5) \n",
    "  \n",
    "    # looping through the faces detect in the image \n",
    "    # getting coordinates x, y , width and height \n",
    "    for (x, y, h, w) in faces: \n",
    "  \n",
    "        # draw the rectangle on the face \n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), GREEN, 2) \n",
    "  \n",
    "        # getting face width in the pixels \n",
    "        face_width = w \n",
    "  \n",
    "    # return the face width in pixel \n",
    "    return face_width \n",
    "  \n",
    "  \n",
    "# reading reference_image from directory \n",
    "ref_image = cv2.imread(r\"D:\\ANACONDA3\\envs\\cam_dist\\refs\\1st.jpg\") \n",
    "  \n",
    "# find the face width(pixels) in the reference_image \n",
    "ref_image_face_width = face_data(ref_image) \n",
    "  \n",
    "# get the focal by calling \"Focal_Length_Finder\" \n",
    "# face width in reference(pixels), \n",
    "# Known_distance(centimeters), \n",
    "# known_width(centimeters) \n",
    "Focal_length_found = Focal_Length_Finder( \n",
    "    Known_distance, Known_width, ref_image_face_width) \n",
    "  \n",
    "print(Focal_length_found) \n",
    "  \n",
    "# show the reference image \n",
    "cv2.imshow(r\"D:\\ANACONDA3\\envs\\cam_dist\\refs\\1st.jpg\", ref_image) \n",
    "  \n",
    "# initialize the camera object so that we \n",
    "# can get frame from it \n",
    "cap = cv2.VideoCapture(0) \n",
    "  \n",
    "# looping through frame, incoming from  \n",
    "# camera/video \n",
    "while True: \n",
    "  \n",
    "    # reading the frame from camera \n",
    "    _, frame = cap.read() \n",
    "  \n",
    "    # calling face_data function to find \n",
    "    # the width of face(pixels) in the frame \n",
    "    face_width_in_frame = face_data(frame) \n",
    "  \n",
    "    # check if the face is zero then not  \n",
    "    # find the distance \n",
    "    if face_width_in_frame != 0: \n",
    "        \n",
    "        # finding the distance by calling function  \n",
    "        # Distance finder function need  \n",
    "        # these arguments the Focal_Length, \n",
    "        # Known_width(centimeters), \n",
    "        # and Known_distance(centimeters) \n",
    "        Distance = Distance_finder(Focal_length_found, Known_width, face_width_in_frame) \n",
    "  \n",
    "        # draw line as background of text \n",
    "        cv2.line(frame, (30, 30), (230, 30), RED, 32) \n",
    "        cv2.line(frame, (30, 30), (230, 30), BLACK, 28) \n",
    "  \n",
    "        # Drawing Text on the screen \n",
    "        cv2.putText( \n",
    "            frame, f\"Distance: {round(Distance,2)} CM\", (30, 35),fonts, 0.6, GREEN, 2) \n",
    "  \n",
    "    # show the frame on the screen \n",
    "    cv2.imshow(\"frame\", frame) \n",
    "  \n",
    "    # quit the program if you press 'q' on keyboard \n",
    "    if cv2.waitKey(1) == ord(\"q\"): \n",
    "        break\n",
    "  \n",
    "# closing the camera \n",
    "cap.release() \n",
    "  \n",
    "# closing the windows that are opened \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d595a793-7ac9-487c-8bd2-aff955ab0c32",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m confidence \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n\u001b[0;32m     30\u001b[0m     class_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(detections[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, i, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m---> 31\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[43mclasses\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclass_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     32\u001b[0m     box \u001b[38;5;241m=\u001b[39m detections[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, i, \u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m7\u001b[39m] \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray([frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], frame\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m     33\u001b[0m     (startX, startY, endX, endY) \u001b[38;5;241m=\u001b[39m box\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load COCO class labels\n",
    "classes = open('coco.names').read().strip().split('\\n')\n",
    "\n",
    "# Load pre-trained MobileNet SSD model\n",
    "net = cv2.dnn.readNetFromTensorflow(r\"D:\\ANACONDA3\\envs\\cam_dist\\measure_distance_using_camera\\frozen_inference_graph.pb\", r\"D:\\ANACONDA3\\envs\\cam_dist\\measure_distance_using_camera\\ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\")\n",
    "\n",
    "# Open a video capture object (use 0 for default camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Prepare the frame for object detection\n",
    "    blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), 127.5)\n",
    "\n",
    "    # Set the input to the network and perform forward pass\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Loop over the detections\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # Filter out weak detections\n",
    "        if confidence > 0.5:\n",
    "            class_id = int(detections[0, 0, i, 1])\n",
    "            label = classes[class_id]\n",
    "            box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # Draw the bounding box and label on the frame\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (startX, startY - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262838a-f2c4-4d69-96c1-dc90384aac0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
